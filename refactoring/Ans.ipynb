{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model.py\n",
    "## Exmaple of Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(1024, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def cnn():\n",
    "    return CNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1f30ba13910>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1f30ba13940>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DataLoader.py\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class loader(object):\n",
    "    def __init__(self, _data='mnist', batch_size=64, type=\"NON_IID\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.type = type\n",
    "        self._data=_data\n",
    "        \n",
    "        self.__load_dataset()\n",
    "        self.__get_index()\n",
    "        \n",
    "\n",
    "    def __load_dataset(self):\n",
    "        # mnist\n",
    "        self.train_mnist = datasets.MNIST('./dataset/',\n",
    "                                          train=True, download=True,\n",
    "                                          transform=transforms.Compose([\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                          ]))\n",
    "\n",
    "        self.test_mnist = datasets.MNIST('./dataset/',\n",
    "                                         train=False, download=True,\n",
    "                                         transform=transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                         ]))\n",
    "\n",
    "    def __get_index(self):\n",
    "        self.train_dataset = self.train_mnist\n",
    "        self.test_dataset = self.test_mnist\n",
    "\n",
    "        #indices-> first item of big list mean the index of 0, first small list mean array of data indices which has 0 \n",
    "        self.indices = [[], [], [], [], [], [], [], [], [], []]\n",
    "        for index, data in enumerate(self.train_dataset):\n",
    "            self.indices[data[1]].append(index)\n",
    "\n",
    "    def get_loader(self, rank):\n",
    "        if not rank:\n",
    "            rank = np.random.randint(10)\n",
    "        else:\n",
    "            rank = int(rank[0])\n",
    "            np.random.seed(rank)\n",
    "        \n",
    "        if self.type == \"NON_IID\":\n",
    "            # 10 classes\n",
    "            num_classes = 10\n",
    "            # 2 shards per class\n",
    "            shards_per_class = 2\n",
    "            # 20 shards in total\n",
    "            total_shards = num_classes * shards_per_class\n",
    "            # shard_size: 3000 samples per shard-> but not exactly 3000(indices[0])\n",
    "            shard_size = len(self.indices[0]) // shards_per_class\n",
    "\n",
    "            # Sort indices for labels -> but why?, result is same, this process is unnecessary\n",
    "            sorted_indices = [sorted(self.indices[i]) for i in range(num_classes)]  \n",
    "\n",
    "            # shards: 20 shards, each shard has 3000 samples//0,10th->label_0//1,11th->label_1\n",
    "            shards = []\n",
    "            for shard_idx in range(total_shards):\n",
    "                #class_idx: current working class\n",
    "                class_idx = shard_idx % num_classes\n",
    "                #start_idx: start index of current shard\n",
    "                start_idx = (shard_idx // num_classes) * shard_size\n",
    "                end_idx = start_idx + shard_size\n",
    "                shards.append(sorted_indices[class_idx][start_idx:end_idx])\n",
    "\n",
    "            # Randomly select 5 shards\n",
    "            selected_classes = random.sample(range(num_classes), 5)  \n",
    "            #pick 2shards from each selected class-> 2([0,10]) X 5 = 10 shards\n",
    "            selected_shards = [shard for class_idx in selected_classes for shard in shards[class_idx::num_classes]]\n",
    "\n",
    "            # but why?,labels1 is overwraped again, this process is unnecessary\n",
    "            for rank, shard in enumerate(selected_shards):\n",
    "                selected_clients = shard\n",
    "                labels1 = [self.train_dataset.targets[idx].item() for idx in selected_clients]\n",
    "\n",
    "            #shard: list of idx-> subset: list of data\n",
    "            subsets = [torch.utils.data.Subset(self.train_dataset, shard) for shard in selected_shards]  \n",
    "            #\n",
    "            train_loader = DataLoader(torch.utils.data.ConcatDataset(subsets), batch_size=self.batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        elif self.type == \"IID\":\n",
    "            num_classes = 10\n",
    "            shards_per_class = 5\n",
    "            total_shards = num_classes * shards_per_class\n",
    "            shard_size = len(self.indices[0]) // shards_per_class  \n",
    "\n",
    "            sorted_indices = [sorted(self.indices[i]) for i in range(num_classes)]  \n",
    "\n",
    "            shards = []\n",
    "            for shard_idx in range(total_shards):\n",
    "                class_idx = shard_idx % num_classes  # Shard index determines label\n",
    "                start_idx = (shard_idx // num_classes) * shard_size\n",
    "                end_idx = start_idx + shard_size\n",
    "                shards.append(sorted_indices[class_idx][start_idx:end_idx])\n",
    "\n",
    "            for rank, shard in enumerate(shards):\n",
    "                selected_clients = shard\n",
    "                labels1 = [self.train_dataset.targets[idx].item() for idx in selected_clients]\n",
    "\n",
    "            subsets = [torch.utils.data.Subset(self.train_dataset, shard) for shard in shards]  \n",
    "            train_loader = DataLoader(torch.utils.data.ConcatDataset(subsets), batch_size=self.batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "loader1 = loader()\n",
    "loader1.get_loader([1])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Client.py\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "class Client(object):\n",
    "    def __init__(self, rank, data_loader, local_epoch, ES):\n",
    "        seed = 19201077 + 19950920 + rank   # ??\n",
    "        torch.manual_seed(seed)\n",
    "        self.accuracy = []\n",
    "        self.rank = rank\n",
    "        self.local_epoch = local_epoch\n",
    "        self.ES=ES\n",
    "        self.device = ES.device\n",
    "        self.test_loader = data_loader[1]\n",
    "        self.train_loader = iter(data_loader[0])    #iter: make iterator??\n",
    "\n",
    "\n",
    "    ## Option\n",
    "    # def test(self, model):\n",
    "    #     test_correct = 0\n",
    "    #     \n",
    "    #     # eval mode on\n",
    "    #     model.eval()\n",
    "    #     device = self.device\n",
    "    \n",
    "    #     with torch.no_grad():\n",
    "    #         for data, target in self.test_loader:\n",
    "    #             data, target = Variable(data).to(device),Variable(target).to(device)\n",
    "    #             output = model(data)\n",
    "    #             pred = output.argmax(dim=1, keepdim=True)\n",
    "    #             test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    #     return test_correct / len(self.test_loader.dataset)\n",
    "\n",
    "    def train(self, model):\n",
    "        #train mode on\n",
    "        model.train()\n",
    "        device = self.device\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False) \n",
    "        chk=0\n",
    "        for data, target in self.train_loader:\n",
    "            chk+=1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            self.loss = nn.CrossEntropyLoss()(output, target)\n",
    "            self.loss.backward()\n",
    "            optimizer.step()    \n",
    "            if(chk ==1):\n",
    "                break\n",
    "            scheduler.step()\n",
    "            \n",
    "        weights=model.state_dict()\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def load_global_model(self):\n",
    "        '''\n",
    "        ES's w-> model's w\n",
    "        '''\n",
    "        model = CNN().to(self.ES.device)\n",
    "        model.load_state_dict(self.ES.model.state_dict()) \n",
    "        return model\n",
    "    \n",
    "    def run(self):\n",
    "        model = self.load_global_model()\n",
    "        for _ in range(self.local_epoch):\n",
    "            weights = self.train(model=model)\n",
    "\n",
    "        self.ES.clients[self.ES.count%self.ES.size]=weights # Client class -> ES class's clients attrubute\n",
    "        self.ES.count+=1                                    # count: each ES's 1 client local training is done\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edge_Server.py\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "#import Client\n",
    "class ES():\n",
    "    def __init__(self, size, data_loader, device, CS=None):\n",
    "        self.size = size\n",
    "        self.test_loader = data_loader[1]\n",
    "        self.accuracy = []\n",
    "        self.clients = [None]*size\n",
    "        self.count = 0\n",
    "        self.model =  CNN().to(device)\n",
    "        self.device = device\n",
    "        self.CS = CS    #CS: Cloud_Server\n",
    "\n",
    "\n",
    "    def average_weights(self,clients):\n",
    "        for nth_Client in clients[1:]:\n",
    "            for key in nth_Client:\n",
    "                clients[0][key]+=nth_Client[key]\n",
    "        for key in clients[0]:\n",
    "            clients[0][key]=clients[0][key]/self.size  \n",
    "        weights=clients[0]\n",
    "        return weights\n",
    "\n",
    "    def aggregate(self):\n",
    "        weights_info = self.clients\n",
    "        weights = self.average_weights(weights_info)\n",
    "        self.model.load_state_dict(weights)\n",
    "        test_accuracy = self.test()\n",
    "        self.accuracy.append(test_accuracy)\n",
    "        # ES\n",
    "        if (self.CS):\n",
    "            # up propagate ES's w-> CS's w\n",
    "            self.upload_global_model()\n",
    "            print('\\n[ES Model]  Test Accuracy: {:.2f}%\\n'.format(test_accuracy * 100.))\n",
    "        # CS\n",
    "        else:\n",
    "            # can not down propagate CS's w-> ES's w\n",
    "            print(\"Cloud Server process : \",end=\"\")\n",
    "            print('\\n**** [CS Model]  Test Accuracy: {:.2f}% ****\\n'.format(test_accuracy * 100.))\n",
    "        \n",
    "    def global_weight(self):\n",
    "        weights = self.model.state_dict()\n",
    "        return weights\n",
    "    \n",
    "    def upload_global_model(self):\n",
    "        self.CS.clients[self.CS.count%self.CS.size]=self.model.state_dict()\n",
    "        self.CS.count+=1\n",
    "    \n",
    "    def load_global_model(self):\n",
    "        '''\n",
    "        CS's w-> ES's w\n",
    "        '''\n",
    "        self.model.load_state_dict(self.CS.model.state_dict()) \n",
    "    \n",
    "    def test(self):\n",
    "        test_correct = 0\n",
    "        self.model.eval()\n",
    "        device = self.device\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "                output = self.model(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        return test_correct / len(self.test_loader.dataset)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cloud_server.py\n",
    "# import Edge_Server\n",
    "\n",
    "class CS(ES):\n",
    "    def __init__(self, size, data_loader, device):\n",
    "        super().__init__(size, data_loader, device)\n",
    "        self.ESs=self.clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main.py\n",
    "import random\n",
    "def fed_AVG(n_client, n_ES, ES_epoch, epoch, batch_size, device = \"cuda\" ,type = \"IID\"):\n",
    "    '''n_client: number of clients per 1 Edge Server'''\n",
    "    \n",
    "    print('Initialize Dataset...')\n",
    "    data_loader = loader('mnist', batch_size=batch_size, type = type)    \n",
    "    print('Initialize Edge Servers and Clients...')\n",
    "    CS_1=CS(size = n_ES, data_loader = data_loader.get_loader([]), device = device)\n",
    "\n",
    "    ESs = []\n",
    "    clients = [[ None for i in range(n_client)] for j in range(n_ES) ]\n",
    "    for i in range(n_ES):\n",
    "        ESs.append(ES(size = n_client, data_loader = data_loader.get_loader([]), device = device, CS=CS_1))\n",
    "        for j in range(n_client):\n",
    "            clients[i][j]=Client(rank=j, data_loader=data_loader.get_loader(\n",
    "            random.sample(range(0, 10), 4)  # distribute 4 classes\n",
    "            ),local_epoch = epoch,\n",
    "            ES = ESs[i])\n",
    "\n",
    "    # federated learning\n",
    "    for ESe in range(ES_epoch):\n",
    "        print('\\n================== Edge Server Epoch {:>3} =================='.format(ESe + 1))\n",
    "        #each edge server's clients run\n",
    "        for ESn in range(n_ES):\n",
    "            print(\"Edge Server :\",ESn,\"process : \",end=\"\")\n",
    "            #each client's local training\n",
    "            for c in clients[ESn]:\n",
    "                c.run()\n",
    "            ESs[ESn].aggregate()\n",
    "        #receive and propagate global model to edge servers\n",
    "        CS_1.aggregate()\n",
    "        \n",
    "        #down propagate CS's w-> ES's w\n",
    "        for ESn in range(n_ES):\n",
    "            ESs[ESn].load_global_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Dataset...\n",
      "Initialize Edge Servers and Clients...\n",
      "\n",
      "================== Edge Server Epoch   1 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 10.11%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 15.11%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 23.22%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 29.42%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 19.40%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 27.15%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   2 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 12.29%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 18.55%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 23.23%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 36.72%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 20.05%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 33.39%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   3 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 21.88%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 31.07%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 42.11%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 38.10%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 24.13%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 58.59%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   4 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 40.14%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 40.05%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 53.21%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 42.53%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 41.00%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 69.63%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   5 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 53.01%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 52.76%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 63.89%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 50.05%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 51.09%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 77.77%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   6 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 61.71%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 66.25%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 71.93%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 59.53%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 65.67%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 80.61%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   7 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 67.59%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 72.67%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 74.87%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 64.73%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 69.87%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 82.23%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   8 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 72.93%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 76.25%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 78.10%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 69.81%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 75.32%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 83.85%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch   9 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 72.64%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 79.74%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 79.36%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 74.42%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 77.85%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 85.18%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch  10 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 74.30%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 81.54%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 80.81%\n",
      "\n",
      "Edge Server : 3 process : \n",
      "[ES Model]  Test Accuracy: 75.52%\n",
      "\n",
      "Edge Server : 4 process : \n",
      "[ES Model]  Test Accuracy: 81.01%\n",
      "\n",
      "Cloud Server process : \n",
      "[CS Model]  Test Accuracy: 85.94%\n",
      "\n",
      "\n",
      "================== Edge Server Epoch  11 ==================\n",
      "Edge Server : 0 process : \n",
      "[ES Model]  Test Accuracy: 75.19%\n",
      "\n",
      "Edge Server : 1 process : \n",
      "[ES Model]  Test Accuracy: 82.59%\n",
      "\n",
      "Edge Server : 2 process : \n",
      "[ES Model]  Test Accuracy: 81.61%\n",
      "\n",
      "Edge Server : 3 process : "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfed_AVG\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNON_IID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m, in \u001b[0;36mfed_AVG\u001b[1;34m(n_client, n_ES, ES_epoch, epoch, batch_size, device, type)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#each client's local training\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m clients[ESn]:\n\u001b[1;32m---> 29\u001b[0m         \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     ESs[ESn]\u001b[38;5;241m.\u001b[39maggregate()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#receive and propagate global model to edge servers\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m, in \u001b[0;36mClient.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_global_model()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_epoch):\n\u001b[1;32m---> 74\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mES\u001b[38;5;241m.\u001b[39mclients[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mES\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mES\u001b[38;5;241m.\u001b[39msize]\u001b[38;5;241m=\u001b[39mweights \u001b[38;5;66;03m# Client class -> ES class's clients attrubute\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mES\u001b[38;5;241m.\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mClient.train\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     49\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 51\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(output, target)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\dongwoo\\anaconda3\\envs\\_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dongwoo\\anaconda3\\envs\\_torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dongwoo\\anaconda3\\envs\\_torch\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fed_AVG(10, 5, 30, 20, 64, \"cuda\", \"NON_IID\")  #n_client, n_ES, ES_epoch, epoch, batch_size, device = \"Cuda:0\" ,type = \"IID\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
