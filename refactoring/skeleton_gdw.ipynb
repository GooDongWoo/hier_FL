{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#DFFF00\">0. model example and preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model.py\n",
    "## Exmaple of Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(1024, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def cnn():\n",
    "    return CNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#DFFF00\">1. Data Loading and distribution</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2bedbb5edd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2beda0f2b50>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Loader-MNIST\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class loader(object):\n",
    "    def __init__(self, batch_size= 64, type =\"NON_IID\"):\n",
    "        self.batch_size = batch_size\n",
    "        self.type = type\n",
    "        self.__load_dataset()\n",
    "        self.__get_index()\n",
    "        \n",
    "    def __load_dataset(self):\n",
    "        # mnist\n",
    "        self.train_mnist = datasets.MNIST('./dataset/',\n",
    "                                          train=True,\n",
    "                                          download=True,\n",
    "                                          transform=transforms.Compose([\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,), (0.3081,))# batch mean, std\n",
    "                                          ]))\n",
    "\n",
    "        self.test_mnist = datasets.MNIST('./dataset/',\n",
    "                                         train=False,\n",
    "                                         download=True,\n",
    "                                         transform=transforms.Compose([\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                         ]))\n",
    "\n",
    "\n",
    "\n",
    "    def __get_index(self):\n",
    "        self.train_dataset = self.train_mnist\n",
    "        self.test_dataset = self.test_mnist\n",
    "        self.indices = [[], [], [], [], [], [], [], [], [], []]\n",
    "        for index, data in enumerate(self.train_dataset):\n",
    "            self.indices[data[1]].append(index)        \n",
    "        \n",
    "    def get_loader(self, rank):\n",
    "        if not rank:  # 빈 리스트인 경우\n",
    "            # 시드 값을 랜덤하게 선택 -> server loader\n",
    "            rank = np.random.randint(100)  # 0부터 99까지의 랜덤한 정수 선택 \n",
    "        else:\n",
    "            rank = int(rank[0])  # 정수형으로 변환\n",
    "            np.random.seed(rank)  # 시드 설정(고정)\n",
    "\n",
    "        if self.type == \"IID\":\n",
    "            num_classes = 10 # 0-9 classes\n",
    "            num_clients = 50 # number of clients\n",
    "            sorted_indices = [sorted(self.indices[i]) for i in range(num_classes)]\n",
    "            label_per_client = len(self.indices[0]) // num_clients\n",
    "            \n",
    "            shards = []\n",
    "            for rank in range(num_clients):\n",
    "                shard = [] \n",
    "                for nc in range(num_classes):\n",
    "                    label_indices = sorted_indices[nc] \n",
    "                    start_idx = rank * label_per_client\n",
    "                    end_idx = start_idx + label_per_client\n",
    "                    selected_indices = label_indices[start_idx:end_idx]\n",
    "                    shard.extend(selected_indices) \n",
    "                shards.append(shard)\n",
    "                \n",
    "            for rank, shard in enumerate(shards):\n",
    "                # Check the labels in each client's shard\n",
    "                labels1 = [self.train_dataset.targets[idx].item() for idx in shard]\n",
    "                #print(f\"Client {rank+1} - Labels of Shard: {labels1}\")\n",
    "\n",
    "            subsets = [torch.utils.data.Subset(self.train_dataset, shard) for shard in shards]\n",
    "            train_loader = DataLoader(torch.utils.data.ConcatDataset(subsets), batch_size=self.batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        elif self.type == \"NON_IID\":\n",
    "            num_classes = 10 # 0-9 classes\n",
    "            num_clients = 50 # number of clients\n",
    "            num_shards = 200 # shards 개수\n",
    "            shard_size = 300 # 300개 예제\n",
    "            sorted_indices = [sorted(self.indices[i]) for i in range(num_classes)] # 데이터를 라벨 별로 정렬\n",
    "            ###############################\n",
    "            ## IID 부분과 논문을 참조하여 작성필요. label을 이용한 subset으로 구현해야합니다. \n",
    "            ## Your Code..\n",
    "            label_per_client = shard_size\n",
    "\n",
    "            shards = []\n",
    "            for rank in range(num_clients):\n",
    "                shard = []\n",
    "                for nc in range(num_classes):\n",
    "                    label_indices = sorted_indices[nc] \n",
    "                    start_idx = rank * label_per_client\n",
    "                    end_idx = start_idx + label_per_client\n",
    "                    selected_indices = label_indices[start_idx:end_idx]\n",
    "                    shard.extend(selected_indices)\n",
    "                shards.append(shard)\n",
    "                \n",
    "            for rank, shard in enumerate(shards):\n",
    "                # Check the labels in each client's shard\n",
    "                labels1 = [self.train_dataset.targets[idx].item() for idx in shard]\n",
    "                #print(f\"Client {rank+1} - Labels of Shard: {labels1}\")\n",
    "\n",
    "            subsets = [torch.utils.data.Subset(self.train_dataset, shard) for shard in shards]\n",
    "            train_loader = DataLoader(torch.utils.data.ConcatDataset(subsets), batch_size=self.batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "            ###############################\n",
    "        return train_loader, test_loader\n",
    "\n",
    "loader_test=loader(type =\"IID\")\n",
    "loader_test.get_loader([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#DFFF00\">2. ES, Client class</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edited day: 2023. 11. 16.\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "#from Model import model ## Define your model\n",
    "#from Data_Loader import loader ## Define your data loader\n",
    "\n",
    "class ES():\n",
    "    def __init__(self, size, data_loader, load, device):\n",
    "        self.size        = size ## Number of Clients\n",
    "        #self.model       = model.to(device)\n",
    "        self.test_loader = data_loader[1] ## Your test dataset\n",
    "        self.accuracy    = []\n",
    "        self.clients     = [None]*size ## Client's parameter memory\n",
    "        self.count       = 0\n",
    "        self.load        = load ## Reflect Client k's data size\n",
    "        self.load_s      = 0 ## Reflect Whole Client's data size\n",
    "        self.device      = device ## Cuda or CPU\n",
    "        for i in load:\n",
    "            self.load_s+=i\n",
    "            \n",
    "    def average_weights(self, clients):\n",
    "        ## Brief: clients리스트에 저장된 각 사용자들의 parameter를 가중평균(load반영) 해줌.\n",
    "        ## Pre: clients 리스트에 사용자들의 parameter가 저장되어 있어야함.\n",
    "        ## Retrun:  가중평균된 weight을 반환.\n",
    "        ## Tip : Torch의 weight은 dictionary형태로 참조 및 합쳐줄 수 있음.\n",
    "        ## 매개변수의 client는 self.clients이나 특정 사용자 subset으로 한정할 수도 있기에 변수화함.\n",
    "\n",
    "    def aggregate(self):\n",
    "        ## Brief: Average된 weight을 global model에 반영 및 test 진행\n",
    "        ## Pre: self.clients에 각 사용자들의 weight이 저장되어 있음\n",
    "        ## Post1: global 모델인 self.model에 averaging된 parameter를 load함.\n",
    "        ## Post2: test accuracy를 메모리에 저장\n",
    "        \n",
    "    def global_weight(self):\n",
    "        ## Brief: 현재 Edge Server에 저장된 Global Weight을 참조\n",
    "        ## Pre: global 모델이 정의되어 있어야함.\n",
    "        ## Retrun:  Global Weight을 반환\n",
    "    \n",
    "    def test(self):\n",
    "        ## Brief: 현재 Global model에 대한 test 함수.\n",
    "        ## Pre: model이 aggregate된 상태여야 함.\n",
    "        ## Return: test score를 반환\n",
    "\n",
    "class Client():\n",
    "    def __init__(self, rank, data_loader, local_epoch, ES):\n",
    "        # seed\n",
    "        seed = 19201077 + 19950920 + rank\n",
    "        torch.manual_seed(seed) ## Random Seed로 random 고정\n",
    "        self.rank = rank ## Clinet's ID\n",
    "        self.local_epoch = local_epoch ## FedAVG's local epoch\n",
    "        self.ES = ES ## Client가 속해있는 Edge Server 인식\n",
    "        self.test_loader = data_loader[1] ## Test data\n",
    "        self.train_loader = iter(data_loader[0]) ## Train data\n",
    "\n",
    "    def load_global_model(self):\n",
    "        ## Brief: 현재 Global model에 대한 test 함수.\n",
    "        ## Pre: model이 aggregate된 상태여야 함.\n",
    "        ## Return: test score를 반환\n",
    "        return model\n",
    "    \n",
    "    def train(self, model):\n",
    "        ## Brief: local model의 학습을 진행.\n",
    "        ## Pre: None\n",
    "        ## Return: 학습된 client k의 weight을 반환.\n",
    "        \n",
    "        # optimizer = optim.SGD() // 모델의 optimizer\n",
    "        # scheduler = optim.lr_scheduler.LambdaLR() // optimizer의 Learning Rate를 epoch에 따라 조절함.\n",
    "        \n",
    "        # for _ in range(local_epoch):\n",
    "            # for data, target in self.train_loader:\n",
    "                #여기서 학습 진행\n",
    "            \n",
    "    def run(self):\n",
    "        model = self.load_global_model(self)\n",
    "        weights = self.train(model)\n",
    "        self.ES.clients[self.ES.count%self.ES.size]=weights\n",
    "        self.ES.count+=1\n",
    "        ## count는 circular buffer용임\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#DFFF00\">3. Run</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def fed_AVG(n_client, n_ES, ES_epoch, CL_epoch, batch_size, type = \"NON_IID\"):\n",
    "    print('Initialize Dataset...')\n",
    "    data_loader = loader('mnist', batch_size=batch_size, type = type)    \n",
    "    print('Initialize Edge Servers and Clients...')\n",
    "    ESs = []\n",
    "    clients = [[ None for i in range(n_client)] for j in range(n_ES) ]\n",
    "\n",
    "    for i in range(n_ES):\n",
    "        #ESs.append(ES()) class 내용과 논문 참조해서 매개변수 작성필요.\n",
    "        for j in range(n_client):\n",
    "            #clients[i][j]=Client() class 내용과 논문 참조해서 매개변수 작성필요.\n",
    "\n",
    "    # Federated Learning\n",
    "    for ESe in range(ES_epoch):\n",
    "        #print('\\n================== Edge Server Epoch {:>3} =================='.format(ESe + 1))\n",
    "        for ESn in range(n_ES):\n",
    "            #print(\"================= Edge Server :\",ESn,\"process =================\")\n",
    "            for c in clients[ESn]:\n",
    "                c.run()\n",
    "                \n",
    "            ESs[ESn].aggregate()\n",
    "\n",
    "        for ESn in range(n_ES):\n",
    "            ESs[ESn].load_global_model()\n",
    "    \n",
    "    w = []\n",
    "    \n",
    "    for es in ESs:\n",
    "        w.append(copy.deepcopy(es.global_weight()))\n",
    "\n",
    "    return w\n",
    "if __name__ == '__main__':\n",
    "    w = fed_AVG()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
